% Created 2013-06-12 Wed 09:10
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fixltx2e}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{soul}
\usepackage{textcomp}
\usepackage{marvosym}
\usepackage{wasysym}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{amstext}
\usepackage{hyperref}
\tolerance=1000
\usepackage{fullpage}
\author{Chris Wallace}
\date{2013-05-22 Wed}
\title{snpBMA: a package for details genetic association analysis of densely typed genetic regions}
\hypersetup{
  pdfkeywords={},
  pdfsubject={},
  pdfcreator={Emacs 24.2.1 (Org mode 8.0.3)}}
\begin{document}

\maketitle
\tableofcontents

%\VignetteIndexEntry{snpBMA analysis}

\section{Bayesian Model Averaging and the BMA package}
\label{sec-1}

\section{Priors}
\label{sec-2}

\section{Simulate some data}
\label{sec-3}

We start with using some sample data from the snpStats package
including 20 SNPs, and simulating a quantitative trait that depends
on 3 causal SNPs.

<<>>=
library(snpStats)
data(for.exercise, package="snpStats")
X <- snps.10[,11:30]
n <- nrow(X)
set.seed(12346)
Y <- rnorm(n,mean=as.numeric(X[,1]))*sqrt(0.1) +
  rnorm(n,mean=as.numeric(X[,5]))*sqrt(0.1) +
  rnorm(n,mean=as.numeric(X[,11]))*sqrt(0.1) +
  rnorm(n)*sqrt(0.7)
(causal <- colnames(X)[c(1,5,11)])
@ %def

\texttt{X} contains some missing genotypes, but no SNPs with such a low call
rate we would worry in a large study.  Still, the rest of the analysis
is easier to interpret for the purposes of a vignette if we fill in
the missing values.

<<>>=
summary(X)
X <- impute.missing(X)
@ %def

Looking at the LD, we see this is a region in which D' (above the
diagonal) is very high, whilst $r^2$ can be high between some SNPs,
and with moderately strong $r^2 \simeq 0.7$ between two of our causal
SNPs:
<<fig=TRUE>>=
ld <- show.ld(X=X)
@ %def
\section{Using BMA to identify the causal variants}
\label{sec-4}

Bayesian model averaging approaches can be slow when the number of
SNPs is very large, as the number of models grows rapidly.  The
simulated data are deliberately small here, so that you can compare
the effect of the different ways we tackle this, which fall into three
categories: 
\section{A full BMA analysis using SNP tagging to quickly cover the model space}
\label{sec-5}
First, we aim to cover the model space more rapidly by focusing on a
tagging subset of SNPs, then expand to include the tagged SNPs only in
the neighbourhood of supported models.  Tags can be selected using the
\texttt{tag} function, where \texttt{tag.threshold} sets the $r^2$ threshold used to
group SNPs.  This function makes use of \texttt{hclust} to do the grouping.
We can see that not all of our causal SNPs will be analysed directly,
but some through tags.

<<>>=
tags <- tag(X, tag.threshold=0.8)
tags[causal]
@ %def

Now we can consider sets of models, fixing the number of SNPs each
time.  

<<>>=
## make a snpBMAdata set
data <- make.data(X, Y,tags=tags,family="gaussian")

## Calculate Bayes Factors for all one SNP models
bma.1 <- bma.nsnps(data, nsnps=1)

## Summarise the SNPs with greatest support
head(ss1 <- snp.summary(bma.1))
@ %def

Although the \texttt{bma.nsnps()} function works for any
number of SNPs, it can be simpler to think of growing your BMA models
from a parent generation (here, all possible one SNP models) to a
child generation (here, all possible two SNP models).  

<<>>=
bma.2 <- bma.grow(data=data, bma=bma.1)
bma.3 <- bma.grow(data=data, bma=bma.2)
bma.4 <- bma.grow(data=data, bma=bma.3)
@ %def

\subsection{Visualizing the results}
\label{sec-5-1}

It can be nice to visualize the support across these generations of
models graphically.  So far, we have assumed each model within a
generation has an equal prior, which seems reasonable in the absence
of specific information about the likely impact of each SNP.
However, it doesn't seem reasonable that all models, regardless of
the number of SNPs, should have equal priors.  Models with smaller
numbers of SNPs should be favoured.  We can implement this by
specifying a prior for the number of SNPs in a model.  \texttt{snpBMA} has
two functions to do this, or you can just create your own numeric vector.

<<>>=
## assume a binomial prior for the number of SNPs with expectation of 3 causal SNPs
## ie exactly the scenario simulated!
priors <- prior.binomial(1:10, n=ncol(X), expected=3)
@ %def

See the help for \texttt{prior.betabinomial} to understand the other
function available, and the difference to a binomial prior.

<<fig=TRUE>>=
## create a graph of BMA results so far
results <- stack(bma.1,bma.2,bma.3,bma.4)
 g<-graphBMA(bma.list=results, priors)

## g is an igraph, so you can do all the usual stuff with it:
g

## visualize
graphView(g)
@ %def

This shows the models according to posterior probabilities \textbf{across the
model space visited}.  One model stands out, with SNPs 0, 1 and 5.
These are 0-based numeric indices of the SNPs included, and we can
identify these SNPs using:

<<>>=
snps0(bma.3)[ as.character(c(0,1,5)) ]
@ %def

but it can be easier just write the top models to screen
<<>>=
top.models(results, priors)
@ %def

\subsection{Add back in the tagged SNPs}
\label{sec-5-2}
We used tagging to span the space quickly.  Once we have found our
favoured models, it makes sense to see how the tagged SNPs in LD with
SNPs in those models change things.  There are a couple of subtleties
here to be aware of however:

\begin{enumerate}
\item the X matrix must be of full rank, which means a small amount of
tagging may always be necessary, say at r$^{\text{2}}$=0.99
\item when two SNPs are in strong LD, fitting both in the model can make
the model uninterpretable.  With snpBMA you can group SNPs so that
at most one of each group is included in any single model.  The
default grouping threshold is r$^{\text{2}}$=0.8, but the optimal value will
depend on your data: with many subjects a higher threshold may be
appropriate, as the SNPs become statistically distinguishable.
\end{enumerate}

<<>>=
## First, tag at r2=0.99
tags.99 <- tag(X, 0.99)

## group remaining snps at r2=0.8, using the first set of tags above as indices
groups <- group.tags(tags, keep=tags.99)
length(groups)
data.99 <- make.data(X, Y, tags=tags.99, family="guassian")
@ %def

Now we decide which tag SNP groups we would like to "expand".  We
choose any SNPs in the top three models, after which the posterior
probabilities appear to tail off:

<<>>=
top.models(results, priors)
expand.snps <- top.snps(results, priors, nmodels=3)
@ %def

Now we can refit all models including these tagged SNPs in their
groups:
<<>>=
bma.e1 <- bma.expand(data.99, bma.1, groups=groups[expand.snps])
bma.e2 <- bma.expand(data.99, bma.2, groups=groups[expand.snps])
bma.e3 <- bma.expand(data.99, bma.3, groups=groups[expand.snps])
bma.e4 <- bma.expand(data.99, bma.4, groups=groups[expand.snps])
@ %def

You can see the model space grows much more quickly.  But the end
result is not dissimilar:

<<fig=TRUE>>=
## create a graph of BMA results so far
expand.results <- stack(bma.e1,bma.e2,bma.e3,bma.e4)
 g.expand<-graphBMA(expand.results, priors)

## visualize
graphView(g.expand)

top.models(expand.results, priors)
@ %def
% Emacs 24.2.1 (Org mode 8.0.3)
\end{document}
