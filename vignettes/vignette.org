#+TITLE:     snpBMA: a package for details genetic association analysis of densely typed genetic regions
#+AUTHOR:    Chris Wallace
#+EMAIL:     chris.wallace@cimr.cam.ac.uk
#+DATE:      2013-05-22 Wed
#+DESCRIPTION:
#+KEYWORDS:
#+LANGUAGE:  en
#+OPTIONS:   H:3 num:t toc:t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:(not LOGBOOK) todo:t pri:nil tags:t

#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+LINK_UP:   
#+LINK_HOME: 
#+XSLT:

#+latex_header: \usepackage{fullpage}
#+latex: %\VignetteIndexEntry{snpBMA analysis}

#+begin_html
<!--
%\VignetteEngine{knitr}
%\VignetteIndexEntry{snpBMA analysis}
-->
#+end_html

* Bayesian Model Averaging and the BMA package

* Priors

* Simulate some data

We start with using some sample data from the snpStats package
including 20 SNPs, and simulating a quantitative trait that depends
on 3 causal SNPs.

#+begin_src R :ravel
library(snpStats)
data(for.exercise, package="snpStats")
X <- snps.10[,11:30]
n <- nrow(X)
set.seed(12346)
Y <- rnorm(n,mean=as.numeric(X[,1]))*sqrt(0.1) +
  rnorm(n,mean=as.numeric(X[,5]))*sqrt(0.1) +
  rnorm(n,mean=as.numeric(X[,11]))*sqrt(0.1) +
  rnorm(n)*sqrt(0.7)
(causal <- colnames(X)[c(1,5,11)])
#+end_src

=X= contains some missing genotypes, but no SNPs with such a low call
rate we would worry in a large study.  Still, the rest of the analysis
is easier to interpret for the purposes of a vignette if we fill in
the missing values.

#+BEGIN_SRC R
summary(X)
X <- impute.missing(X)
#+END_SRC

Looking at the LD, we see this is a region in which D' (above the
diagonal) is very high, whilst $r^2$ can be high between some SNPs,
and with moderately strong $r^2 \simeq 0.7$ between two of our causal
SNPs:
#+begin_src R :ravel fig=TRUE
ld <- show.ld(X=X)
#+end_src

* Using BMA to identify the causal variants

Bayesian model averaging approaches can be slow when the number of
SNPs is very large, as the number of models grows rapidly.  The
simulated data are deliberately small here, so that you can compare
the effect of the different ways we tackle this, which fall into three
categories: 

* A full BMA analysis using SNP tagging to quickly cover the model space
First, we aim to cover the model space more rapidly by focusing on a
tagging subset of SNPs, then expand to include the tagged SNPs only in
the neighbourhood of supported models.  Tags can be selected using the
=tag= function, where =tag.threshold= sets the $r^2$ threshold used to
group SNPs.  This function makes use of =hclust= to do the grouping.
We can see that not all of our causal SNPs will be analysed directly,
but some through tags.

#+begin_src R 
tags <- tag(X, tag.threshold=0.8)
tags[causal]
#+end_src

Now we can consider sets of models, fixing the number of SNPs each
time.  

#+begin_src R
## make a snpBMAdata set
data <- make.data(X, Y,tags=tags,family="gaussian")

## Calculate Bayes Factors for all one SNP models
bma.1 <- bma.nsnps(data, nsnps=1)

## Summarise the SNPs with greatest support
head(ss1 <- snp.summary(bma.1))
#+end_src

Although the =bma.nsnps()= function works for any
number of SNPs, it can be simpler to think of growing your BMA models
from a parent generation (here, all possible one SNP models) to a
child generation (here, all possible two SNP models).  

#+BEGIN_SRC R
bma.2 <- bma.grow(data=data, bma=bma.1)
bma.3 <- bma.grow(data=data, bma=bma.2)
bma.4 <- bma.grow(data=data, bma=bma.3)
#+END_SRC

** Visualizing the results

It can be nice to visualize the support across these generations of
models graphically.  So far, we have assumed each model within a
generation has an equal prior, which seems reasonable in the absence
of specific information about the likely impact of each SNP.
However, it doesn't seem reasonable that all models, regardless of
the number of SNPs, should have equal priors.  Models with smaller
numbers of SNPs should be favoured.  We can implement this by
specifying a prior for the number of SNPs in a model.  =snpBMA= has
two functions to do this, or you can just create your own numeric vector.

#+begin_src R
## assume a binomial prior for the number of SNPs with expectation of 3 causal SNPs
## ie exactly the scenario simulated!
priors <- prior.binomial(1:10, n=ncol(X), expected=3)
#+end_src

See the help for =prior.betabinomial= to understand the other
function available, and the difference to a binomial prior.

#+BEGIN_SRC R :ravel fig=TRUE
## create a graph of BMA results so far
results <- stack(bma.1,bma.2,bma.3,bma.4)
 g<-graphBMA(bma.list=results, priors)

## g is an igraph, so you can do all the usual stuff with it:
g

## visualize
graphView(g)
#+END_SRC

This shows the models according to posterior probabilities *across the
model space visited*.  One model stands out, with SNPs 0, 1 and 5.
These are 0-based numeric indices of the SNPs included, and we can
identify these SNPs using:

#+BEGIN_SRC R
snps0(data)[ as.character(c(0,1,5)) ]
#+END_SRC

but it can be easier just write the top models to screen
#+BEGIN_SRC R
top.models(results)
#+END_SRC


** Add back in the tagged SNPs
We used tagging to span the space quickly.  Once we have found our
favoured models, it makes sense to see how the tagged SNPs in LD with
SNPs in those models change things.  There are a couple of subtleties
here to be aware of however:

1. the X matrix must be of full rank, which means a small amount of
   tagging may always be necessary, say at r^2=0.99
2. when two SNPs are in strong LD, fitting both in the model can make
   the model uninterpretable.  With snpBMA you can group SNPs so that
   at most one of each group is included in any single model.  The
   default grouping threshold is r^2=0.8, but the optimal value will
   depend on your data: with many subjects a higher threshold may be
   appropriate, as the SNPs become statistically distinguishable.

#+BEGIN_SRC R
## First, tag at r2=0.99
tags.99 <- tag(X, 0.99)

## group remaining snps at r2=0.8, using the first set of tags above as indices
groups <- group.tags(tags, keep=tags.99)
length(groups)
data.99 <- make.data(X, Y, tags=tags.99, family="guassian")
#+END_SRC

Now we decide which tag SNP groups we would like to "expand".  We
choose any SNPs in the top three models, after which the posterior
probabilities appear to tail off:

#+BEGIN_SRC R
top.models(results, priors)
expand.snps <- top.snps(results, priors, nmodels=3)
#+END_SRC

Now we can refit all models including these tagged SNPs in their
groups:
#+BEGIN_SRC R
bma.e1 <- bma.expand(data.99, bma.1, groups=groups[expand.snps])
bma.e2 <- bma.expand(data.99, bma.2, groups=groups[expand.snps])
bma.e3 <- bma.expand(data.99, bma.3, groups=groups[expand.snps])
bma.e4 <- bma.expand(data.99, bma.4, groups=groups[expand.snps])
#+END_SRC

You can see the model space grows much more quickly.  But the end
result is not dissimilar:

#+BEGIN_SRC R :ravel fig=TRUE
## create a graph of BMA results so far
expand.results <- stack(bma.e1,bma.e2,bma.e3,bma.e4)
 g.expand<-graphBMA(expand.results, priors)

## visualize
graphView(g.expand)

top.models(expand.results, priors)
#+END_SRC

** Speedup 2: excluding SNPs with low single SNP support
We can consider an additional way to prune the model space: exclude
SNPs with very limited single SNP support.  In this case, we drop
SNPs that have a 2 log Bayes Factor (versus the null model with no
SNPs) < 2.2, a threshold previous described as "weak support".

#+begin_src R
## define the list of SNPs to drop
max.bf <- apply(ss1,1,max)
snps.drop <- rownames(ss1)[ max.bf < 2.2 ]
snps.drop
#+end_src

Then we can assess all two SNP models excluding those in snps.drop.  We
will also analyse the complete set of data, so the two approaches can
be compared.  To do this, we
need to prune the snps included in the =bma.1= object and the =data= object.

#+begin_src R

## generate a new set of tags and snpBMAdata object
tags <- tags[!(tags %in% snps.drop)]
data2 <- make.data(X, Y,tags=tags,family="gaussian")

bma.2 <- bma.nsnps(data, nsnps=2)
bma.2d <- bma.nsnps(data2, nsnps=2)
#+end_src

** Excluding unlikely models
Models with two or more SNPs can be thought of as children of many
parent models.  If a two SNP model contains SNPs A and B, then its
parents are the single SNP models containing either A or B.  Each
parent model has many potential children.  Thus the model space can
be partitioned into generations, with each generation containing a
fixed number of SNPs.  Any two or more SNP model can be reached via
multiple paths in this model space.

\cite{madigan94} proposed that where child models had a parent with
greater support than the child, no further "grandchild" models would
be worth considering.  This is quite a broad pruning.  We choose to
implement a variation where the future generation models are excluded
if a child model has a parent model with $f$-fold greater support,
and have set the default at $f=10$.

Here, we compare the child and parent models in =bma.1= and =bma.2d=
to determine the set of models we will not explore.  One way to
implement this would be to determine all the possible three SNP
models, then delete those that are children of the dropped models.
But a faster way is to drop these models from the =bma2= object, then
use =bma.grow()= to automatically fit all the child models of those
which remain.

#+NAME: BMA3
#+BEGIN_SRC R
priors <- prior.binomial(1:10, n=ncol(X), expected=3)

## prune the bma.2d object
bma.2dd <- models.prune(parents=bma.1, children=bma.2d, 
                        prior.parents=priors[1],
                        prior.children=priors[2])

## grow the BMA to a third generation
bma.3dd <- bma.grow(data2, bma.2dd)

## for comparison, without pruning, we could use tagging only...
bma.3 <- bma.nsnps(data, nsnps=3)

## ... or tagging + excluding poorly supported single SNPs
bma.3d <- bma.nsnps(data2, nsnps=3)

## this should be the same as growing from the bma.2d object
bma.3d2 <- bma.grow(data2, bma.2d)

bma.3d
bma.3d2
#+END_SRC


* Automating the analysis

There are a lot of steps above.  It's good to understand the detail
of how we approach the problem, but once you understand it, it can be
tedious to run each step.  We have a function, =bma.auto()=, that
should automate much of this.

TODO!!!

#+begin_src LATEX
\bibliographystyle{plain}
\bibliography{ProbePosition}
#+end_src

